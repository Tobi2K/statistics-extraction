Hasbach^1,2 and Maren Bennewitz^2 	ICRA Workshop on Human-Swarm Interaction 2020 	^1Jonas D
B-.05emi-.025em b-.08emT-.1667em.7exE-.125emX              2020 2020 acmlicensed[MobileHCI '20]22nd International Conference on Human-Computer Interaction with Mobile Devices and ServicesOctober 5–8, 2020Oldenburg, Germany 22nd International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '20), October 5–8, 2020, Oldenburg, Germany 15.00 10.1145/3379503.3403563 978-1-4503-7516-0/20/10                            Comparing IPA use for native and non-native language speakers]See what I'm saying? Comparing Intelligent Personal Assistant use for Native and Non-Native Language Speakers        University College Dublin yunhan.wu@ucdconnect.ie   University College Dublin daniel.rough@ucd.ie   University College Dublin anna.bleakley@ucdconnect.ie   University College Dublin justin.edwards@ucdconnect.ie   University College Dublin orla.cooney@ucdconnect.ie   University College Dublin philip.doyle1@ucdconnect.ie   Swansea University l.m.h.clark@swansea.ac.uk   University College Dublin benjamin.cowan@ucd.ie           Limited linguistic coverage for Intelligent Personal Assistants (IPAs) means that many interact in a non-native language
Hasbach is with the Department of Human-Machine-Systems, Fraunhofer FKIE, 		Wachtberg, Germany. 		jonas.hasbach@fkie.fraunhofer.de 	^2Jonas D
Through native (L1) and non-native (L2) English speakers interacting with Google Assistant on a smartphone and smart speaker, we aim to understand this more deeply
Hasbach and Maren Bennewitz are with the Humanoid Robots Lab, Computer Science, 		University of Bonn, Germany. 		maren@cs.uni-bonn.de      October 9, 2022 =========================================================================================================================================================================================================================================================================================================================================================================================================  empty 	empty 		Human-swarm interaction (HSI) is an active research challenge in the realms of swarm robotics and human-factors engineering
Interviews revealed that L2 speakers prioritised utterance planning around perceived linguistic limitations, as opposed to L1 speakers prioritising succinctness because of system limitations
Reasons are (1) the swarm's inability to achieve mission goals independently <cit.>, (2) human out of loop phenomena <cit.> as well as (3) legal and ethical concerns <cit.>.
 The objective of human-swarm interaction (HSI) <cit.> is to combine the distributed nature of robot swarms with the centralized control and feedback demands of humans into one loop <cit.>
L2 speakers see IPAs as insensitive to linguistic needs resulting in failed interaction
L2 speakers clearly preferred using smartphones, as visual feedback supported diagnoses of communication breakdowns whilst allowing time to process query results
Conversely, L1 speakers preferred smart speakers, with audio feedback being seen as sufficient Daniel2018 look at overarching quality enhancement mechanisms in crowdsourcing
We discuss the need to tailor the IPA experience for L2 users, emphasising visual feedback whilst reducing the burden of language production.          <ccs2012> <concept> <concept_id>10003120.10003121.10003122.10003334</concept_id> <concept_desc>Human-centered computing User studies</concept_desc> <concept_significance>500</concept_significance> </concept> <concept> <concept_id>10003120.10003121.10003124.10010870</concept_id> <concept_desc>Human-centered computing Natural language interfaces</concept_desc> <concept_significance>500</concept_significance> </concept>  <concept> <concept_id>10003120.10011738.10011774</concept_id> <concept_desc>Human-centered computing Accessibility design and evaluation methods</concept_desc> <concept_significance>300</concept_significance> </concept>  </ccs2012>   [500]Human-centered computing User studies [500]Human-centered computing Natural language interfaces [300]Human-centered computing Accessibility design and evaluation methods               [     Benjamin R
Cowan     October 9, 2022 =====================      § INTRODUCTION  The proliferation of voice based Intelligent Personal Assistants (IPAs) like Google Assistant, on smart speakers and smartphones, has made speech a common interaction modality <cit.>
While Daniel2018 summarise task assignment methods, they are not analysed in detail due to the broader scope of their survey.  Zheng2017TruthInference examine 17 truth inference techniques such as majority vote, Zencrowd <cit.> and Minimax <cit.>
However, we provide a summary of truth inference methods in Section <ref>, under post-processing data quality improvement methods.  Li2016CrowdsourcedSurvey surveys crowdsourced data management with an emphasis on different crowd data manipulation operations such as selection, collection and join
Prominent work in HCI looks at IPA user experience <cit.> almost exclusively from the perspective of first language (L1) English speakers, leaving the experience of users who engage with IPAs in a non-native language (such as L2 speakers) unclear.    The work presented contributes important insight into how L2 speakers experience IPAs
Their survey organises prior work under quality, cost and latency control methods. vaughan2017making also present a comprehensive review on how crowdsourcing methods can benefit machine learning research.   Overall, in contrast to prior literature reviews, our survey sheds light on the task assignment problem in crowdsourcing and discusses related assignment based quality improvement methods
Our work aims to 1) map significant dimensions of L2 user experience whilst also 2) identifying how aspects of the two most popular devices for IPA use (smartphones and smart speakers <cit.>)  support or hinder L2 users
We included articles published from 2010 and retrieved 747 records
We also compare this to L1 speaker experiences so as to emphasise the contrasting needs of these speaker groups
To achieve this we carried out a study where, following interactions with Google Assistant on both a smartphone and on a smart speaker,  L1 and L2 English speakers took part in a semi-structured interview devised to gain insight into their experiences
Unpaid or voluntary crowd work is also completed in popular platforms and projects like Wikipedia[https://www.wikipedia.org], Moral Machine <cit.>, Crowd4U <cit.>, Zooniverse[https://www.zooniverse.org], and Test My Brain <cit.>
Our results highlight a number of clear differences between L1 and L2 speakers' perceptions and experiences of IPA use
Little2010ExploringProcesses shows that the iterate and vote method works well on brainstorming and transcription tasks
2019                   rm                      /Title (Developing Computational Models of Social Assistance to Guide Socially Assistive Robots) /Author (Jason R
We found L1 and L2 speakers varied in their interaction approaches, whereby L2 speakers focused heavily on their pronunciation as opposed to L1 emphasising the need for simple, succinct and well planned utterances
For instance, the assess, justify & reconsider <cit.> workflow improves task accuracy by 20% over the majority vote for annotation tasks
Wilson, Seongsik Kim, Ulyana Kurylo, Joseph Cummings, Eshan Tarneja    Northwestern University   2233 Tech Drive   Evanston, IL 60208   jrw@northwestern.edu,{josephkim,uk,jcummings,eshan}@u.northwestern.edu          October 9, 2022 ================================================================================================================================================================================================================================     While there are many examples in which robots provide social assistance, a lack of theory on how the robots should decide how to assist impedes progress in realizing these technologies
Both emphasised the need for speech adaptation, informed by perceived system limitations, yet L2 speakers' adaptation were also driven by their own perceived linguistic limitations
Su2012CrowdsourcingDetection show that data quality in a bounding box task is improved when they employ the annotate and verity method with two quality and coverage assessment tasks followed by the drawing task <cit.>.  More complex workflows that facilitate real-time group coordination <cit.> can be challenging to incorporate into a crowdsourcing platform
Dow2012 report that external expert feedback and self-assessment encourages workers to revise their work.  Dow2012 highlight three key aspects of feedback for crowd work.  `Timeliness' indicates when the worker gets feedback ( synchronously or asynchronously)
Whereas L1 speakers felt the IPA waited too long to speak after they gave a command, L2 speakers felt the assistant was not sensitive enough to the extra time they needed to produce their command and process the system's utterances
This resulted in the system regularly interrupting L2 speakers
We start by looking at the textual content of what is said in a conversation, building upon recent work in recognizing emotions in short conversations - which provide more context than a single utterance.   Using a large data set of short Twitter conversations <cit.>, we developed a Bayesian model to categorize then end of the conversation as being one of three emotions: happiness, sadness, or anger <cit.>.  Our model performed on par with a baseline deep learning model while requiring 1/6 the data and 1/70 of the time to train
While expert and peer feedback are effective in improving data quality, it is challenging to ensure the timeliness of feedback which is important when implementing a scalable feedback system.  It is also possible to deploy a feedback-driven dedicated training task and let workers complete multiple training questions until they achieve a specified data quality threshold.  park2014toward report that such a mechanism can be effective in crowdsourcing tasks that involve complex tools and interfaces
For example, in the HTN in Figure 1, an  action can be included in the plan for the methods  and , and which method is used to create the plan can be used to justify the action
For example, prior work by manam2018wingit proposes a Q&A and Edit feature that workers can use to clarify and improve task instructions or questions.  Other similar work tools that can potentially help improve data quality include third-party web platforms, browser extensions and scripts ( Turkopticon <cit.>, Panda Crazy[https://github.com/JohnnyRS/PandaCrazy-Max]) <cit.>
L2 speakers consistently expressed the desire for IPA design to support lexical retrieval or reduce the need for language production, yet this was not a concern for L1 speakers
More formally, we register following hypothesis to be validated in future work:          (H1)  A person being assisted in a task will feel more autonomous if the assistance provided matches the amount of need for assistance.   This hypothesis assumes that we can measure and infer how much need for assistance a person has.  To this end, we have validated that models of mutual gaze and confirmatory gaze are good indicators of when a person needs assistance <cit.>, and we are in progress on validating models for task progress, lexical cues, and emotion.  Our hypothesis also requires us to be able to knowing how much autonomy a person being assisted has, we need a measure of autonomy
A training set or a gold standard question set can be used when determining the threshold.  Zhuang2015 examined the bias that can be introduced into crowdsourcing when a worker provides answers to multiple tasks grouped into a batch, which is a common mechanism employed to reduce cost and improve convenience for the worker
Instead, we need to measure a transient sense of autonomy that is in direct response to the receiving assistance on a task.  As a result, we are developing a new measure of autonomy, which is currently being validated in experiments in which a person receives assistance and answers a survey of 94 items that reflect issues of autonomy (i.e., authorship,  interest-taking, and susceptibility to control).                                 § MODEL OF SOCIAL ALLIANCE        A model of social alliance, which includes recognizing the goals and intentions of the user,   is used to ensure that a robot is able to build a cooperative alliance with the human user(s) in which the goals of the user(s) are aligned with the goals of the robot
Ma2015FaitCrowd proposed a truth inference method that is able to account for the varying expertise of workers across different topics.   For rating and filtering tasks, DasSarma2016 proposed an algorithm for finding the global optimal estimates of accurate task answers and worker quality for the underlying maximum likelihood problem
L2 speakers significantly preferred using IPAs on smartphones, because they provided visual feedback that supported their interaction
In contrast, L1 speakers preferred smart speakers, with audio feedback being seen as sufficient to support interaction
If the robot has a prior example of the person not taking actions because the person does not intend to do the task, then AToM can be used to infer that the person has similar intentions in the current task.                                                                      	    §.§ Proposed Hypothesis and Model Validation              Since we propose  that a robot can build a social alliance by ensuring that the goals of the robot and the user align, we formulate the following hypothesis to be used to validate our model:         (H1) Goal alignment positively contributes to the building of a social alliance.                       To measure the dependent variable, social alliance, we will use a standard measure used in clinical settings, the Working Alliance Inventory <cit.>
Further, in an extensive survey on truth inference, Zheng2017TruthInference evaluate the performance of different truth inference algorithms.       §.§.§ Clustering   Kairam2016PartingCrowds proposed an automated clustering-based method as a design pattern for analysing crowd task responses
In addition to being used in clinical practice, the Working Alliance Inventory uses in HRI research include   measuring fluency <cit.> and evaluating a relational robot <cit.>.   While building a social alliance is the ultimate goal of this model, it requires that the robot is able to infer the goals of the user.  As a result, we also need to evaluate how well our model is able to make this inference.  As such, we have the following sub-hypotheses:         (H1a) Inferring a user's goal can indicate whether the goals of the user and the robot align.        (H1b) Whether a goal of the user is to perform a task or not may be inferred from the user's actions.                                                                                            § CONCLUSION   These models are not divorced from each other but have many important connections
Our findings build on recent interest in L2 speakers <cit.>, contributing a deeper insight into L2 IPA experiences across these device types
Instead of using worker responses as the sole quality signal, Moshfeghi2016IdentifyingPlatforms propose a method that uses task completion time to identify careless workers
KhudaBukhsh2014DetectingCrowdsourcing propose an unsupervised collusion detection algorithm that can help identify such workers and remove corresponding responses
Our findings emphasise the need to consider L2 user needs so as to be more inclusive of this group
Our work suggests that tailoring IPA interaction by being sensitive to the time needed by L2 users, concentrating on visual feedback and reducing the need for language production in interaction are key design priorities to support L2 users.     § RELATED WORK     §.§ Interacting with Intelligent Personal Assistants  Recent research in HCI has predominantly focused on understanding IPA user experience from the L1 perspective
The amount of work on IPA use among L2 speakers is limited, with research being preliminary and questionnaire based in nature <cit.>, or focused on L2 language learning technology experience <cit.>
Recent quantitative research suggests that L2 speakers find smart speakers harder to use <cit.> and more difficult to interact with effectively than L1 speakers <cit.>, with language proficiency being related to more positive experience ratings <cit.>.  Although they enjoy the interaction, L2 speakers feel they have to expend considerable effort when planning their utterances <cit.>
Rephrasing commands also leads L2 speakers to become frustrated <cit.>
For each question q ∈ Q, multiple workers can provide answers ( A_q,w1, A_q,w2, .
For example, Assadi2015OnlineMarkets investigate task assignment with the aim of maximising the number of tasks allocated with a fixed budget.  § WORKER PERFORMANCE ESTIMATION    Worker performance estimation is a critical step in online assignment process
IPA use has also been explored as a tool to help L2 users improve language skills <cit.> as they afford L2 speakers an opportunity to practise listening to speech output and produce speech input in a stress free context <cit.>
This work has noted that, although they may not be perceived as such <cit.>, IPAs are adept at recognising accented speech accurately in these contexts, whilst providing a useful tool for L2 language learners <cit.>
Accuracy is typically a number between 0 (incorrect) and 1 (correct) and can be defined in different ways depending on the task
Non native speakers were more dissatisfied with speech outputs when they used accents that varied from their own <cit.> whilst non-native speakers also failed to respond to information provided by spoken navigation systems in accents that were dissimilar to their own <cit.>.     §.§ Non-native speaker interaction experiences  Non-native speaker’s interaction experiences, such as their experiences of web page readability and internet search, have also been studied, revealing more general HCI difficulties L2 speakers may face
For instance, for a classification task with single correct answer, accuracy of each question would be 1 if the worker provides the correct label and 0 otherwise
For example, quality of a specific worker could be 0.5 for sentiment analysis task and 0.8 for classification task.      §.§.§ Confusion Matrix   Confusion matrix is extensively used to model worker performance for multiple-choice questions where each question has a fixed number of possible answers (  <cit.>)
Web page readability studies have shown that vocabulary retrieval and parsing of complex grammatical structures are two major difficulties for L2 speakers when reading English pages <cit.>
Likewise, a study of online search found L2 users to have particular difficulties in query formation due to both vocabulary limitations and grammatical phrasing
For instance, Mavridis2016UsingCrowdsourcing uses a skill taxonomy modelled as a tree where nodes represent elementary skills
Prior work by liu2013scoring investigates the optimum number of gold questions to use in a task
This work also found that repair strategies such as rephrasing are much more difficult for L2 users and add to technology-related stress <cit.>
While these difficulties are found in non-native use of written language in technology use, we expect that L2 users may experience similar challenges in speech based interactions with technology.     § RESEARCH AIMS  Most IPA user experience research has focused on identifying issues in L1 speaker interactions
Oleson2011ProgrammaticCrowdsourcing present a programmatic approach to generate gold standard data
Woods 3]Rainer Böhme  [1]University of Innsbruck, Austria, E-mail: maximilian.hils@uibk.ac.at [2]University of Innsbruck, Austria, E-mail: daniel.woods@uibk.ac.at [3]University of Innsbruck, Austria, E-mail: rainer.boehme@uibk.ac.at           < g r a p h i c s >      Proceedings on Privacy Enhancing Technologies 10.2478/popets-2021-0069 249 2021-02-28 2021-06-15 2021-06-16    2021 4     Privacy preference signals are digital representations of how users want their personal data to be processed
Recent work on L2 speakers has used more quantitative approaches to explore their experiences
For instance, hung2015minimizing propose a probabilistic model for classification tasks that help us find a subset of answers to validate through experts
Gadiraju2017UsingMicrotasks show that self-assessment can be a useful performance indicator when we account for varying levels of accuracy in worker self-assessments.      §.§.§ Using Current Answer Distribution   In an ongoing task, we can also use the current answer distribution to estimate worker accuracy
Such signals must be adopted by both the sender (users) and intended recipients (data processors).  Adoption represents a coordination problem that remains unsolved despite efforts dating back to the 1990s.  Browsers implemented standards like the Platform for Privacy Preferences (P3P) and Do Not Track (DNT), but vendors profiting from personal data faced few incentives to receive and respect the expressed wishes of data subjects.  In the wake of recent privacy laws, a coalition of AdTech firms published the Transparency and Consent Framework (TCF), which defines an opt-in consent signal.   This paper integrates post-GDPR developments into the wider history of privacy preference signals.   Our main contribution is a high-frequency longitudinal study describing how TCF signal gained dominance as of February 2021.  We explore which factors correlate with adoption at the website level.  Both the number of third parties on a website and the presence of Google Ads are associated with higher adoption of TCF
Our works builds on this through using qualitative techniques to more deeply investigate the experiences of L2 speakers
To this end, our paper presents research that aims to identify important issues in L2 IPA user experience, emphasising these issues through a contrast with L1 speaker experiences
The method examines all the current answers and iteratively updates worker quality values and task answers until they converge.  Khan2017CrowdDQS used a different approach that uses Marginal Likelihood Estimation
Further, we show that vendors acted as early adopters of  and provide two case-studies describing how Consent Management Providers shifted existing customers to .   We sketch ways forward for a pro-privacy signal.  	 Privacy Preference Signals: Past, Present and Future     [     October 9, 2022 ====================================================        § INTRODUCTION     Privacy preference signals are digital representations of how users want their personal data to be processed.   These vary from a binary “Do Not Track” signal through to more complex expressions in cookie consent dialogues.    Such signals are intended to influence how entities including websites and third parties process personal data.  Web actors may collect privacy preferences in the hope of legitimizing data processing in the eyes of customers or to satisfy legal obligations.     Efforts to standardize privacy preferences go back to at least P3P, which was presented as a prototype to US regulators in 1997 and recommended as a standard by the World Wide Web Consortium (W3C) in 2002.   It was adopted by around 20k websites <cit.>, but was criticized by privacy advocates for not establishing consequences for false reporting of privacy practices <cit.>.   Another W3C working group was formed in 2011 to specify the Do Not Track HTTP extension but it was closed before completion, citing the lack of planned support among “the ecosystem at large” <cit.> as exemplified by the Interactive Advertising Bureau's withdrawal <cit.>.   The first wave of privacy preference signals is completed by the opt-out cookies <cit.> created by the Network Advertising Initiative (NAI) as part of a regulatory compromise with the Federal Trade Commission <cit.>.  The NAI never published a specification, the opt-out only concerned a narrow definition of tracking, and very few vendors participated <cit.>.   A second wave of privacy preference signals was prompted by the passage of privacy laws like the EU General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA).   For example, the GDPR establishes that an opt-in consent signal may constitute a legal basis for processing personal data providing the consent was “freely given, specific, informed and unambiguous”.   These laws prompted research that has largely focused on the interfaces through which opt-in <cit.> and opt-out <cit.> signals are collected
They report that compared to Expectation Maximisation, Marginal Likelihood Estimation significantly reduces root mean squared error (RMSE) in predicting worker accuracy when there are few votes per worker. raykar2012eliminatingranking considers a discrete optimisation problem and propose a Bayesian approach that can estimate a binary state that decides whether a worker is a spammer or not.   Estimating worker accuracy from current answer distribution is not exclusive to labelling tasks
Both sides invested resources in P3P and DNT working groups.  The latter posed a threat to AdTech business models as evidenced by the Interactive Advertising Bureau withdrawing from the working group after Microsoft announced it would be turned on by default <cit.>.   The power of these signals can also be seen in websites' dark patterns that nudge users towards expressing certain preferences <cit.>
Our work is the first to directly compare L1 and L2 users’ experiences of an off-the-shelf IPA across these device platforms
In both P3P and DNT, the user expresses preferences to a user agent.  In contrast, user preferences are collected by embedding an interface in a web page in both of the approaches developed by AdTech industry bodies, namely the Interactive Advertising Bureau (IAB) <cit.> and the Network Advertising Initiative (NAI) <cit.>.   This bypasses browsers by making the signal backwards compatible with existing technology.  Turning to semantics, AdTech vendors proposed opt-in signals that could represent compliance, whereas privacy advocates proposed (global) opt-out signals that empower users.  In summary, these signals have a long history and also have privacy implications going forward.             This paper systematizes historical knowledge on privacy preference signals (the past), measures which signals have been adopted as of February 2021 (the present), and reflects on adoption strategies for a pro-privacy signal (the future).  We show a grim state of affairs for user control over privacy: P3P is obsolete, NAI's system still has only  participating AdTech firms, and the reincarnation of Do Not Track—the Global Privacy Control—has been adopted by less than 10 websites.  Meanwhile, the Interactive Advertising Bureau's  and  have been adopted by thousands of websites.  We then use high-frequency web measurements to build a longitudinal case-study of how adoption and  migration varied over time, websites and AdTech vendors.   Our contributions include:  	   * Systematize knowledge about first wave (P3P, DNT, and NAI opt-out) and second  wave (TCF and GPC) privacy preference signals. 	   * Measure present day adoption and show that TCF adoption is roughly comparable to historical P3P adoption among websites, whereas an order of magnitude more AdTech vendors have adopted TCF than all other signals combined. 	   * Test explanatory variables for TCF adoption like website popularity, category, number of embedded third parties, and presence of Google Ads.  TCF adoption is higher among websites with closer ties to AdTech. 	   * Longitudinal case-study exploring  migration strategies among the two most popular Consent Management Platforms, and how the new version changed the legal basis that individual AdTech vendors claim for tracking.       Section <ref> describes the five privacy preference signals and Section <ref> identifies related work measuring their adoption.   This motivates our empirical measurements, which are described in Section <ref>.  Our results describing the present are contained in Section <ref>.   Section <ref> discusses the past, present and future of privacy preferences.  We conclude in Section <ref>.      § BACKGROUND     This section compares five privacy preference signals in terms of design properties and real-world adoption, which is summarized in Table <ref>.  We selected these signals because they were the most widely adopted among the key stakeholders, namely browsers, AdTech vendors and websites.  We do not provide a background on the widespread online tracking that motivate privacy preference signals, such as cookies <cit.> and other tracking technologies <cit.>.   Similarly, we do not consider privacy preserving technologies unless they function to express privacy preferences, such as when browsers/add-ons collect user preferences and automate sending the signal.  We now turn to the five signals
Baba2013 introduced a two-stage workflow with a creation and a review stage for tasks with unstructured responses, such as content generation and language translation
For example, in a content analysis task that involves assessing US political blogs, Shaw2011 have shown that US workers unsurprisingly perform significantly better than Indian workers.          In contrast, in an attempt to examine the preference for games over conventional tasks in relevance labelling,  Eickhoff2012 reported no significant difference in the performance of workers from the US and India in Amazon Mechanical Turk
Figure <ref> provides and overview of the key events for each signal and Figure <ref> provides a visual summary of the signal's flow.        §.§ Platform for Privacy Preferences (P3P)      P3P is one of the earliest privacy preference signals proposed for the Web
Other work have also shown that worker demographics can introduce biases to the data collected <cit.>.        * Personality: Kazai2011 analysed crowd users based on five personality dimensions introduced by Goldberg <cit.> known as the `Big Five'
A demonstration of a P3P prototype was presented before the FTC in June 1997.  The W3C recommended the P3P 1.0 specification in 2002, which describes an XML format to encode a human-readable privacy policy into a machine-readable specification stating the type, recipients and purposes of data collected
Users can define individual privacy preferences, which browsers can cross-check against a website's self-reported P3P policy
In a subsequent study, Kazai2012 also reported that the Big Five personality traits - openness and conscientiousness - are correlated with higher task accuracy
Lykourentzou2016 also examined the effect of personality on the performance of collaborative crowd work on creative tasks
Across the sample 78.1%  (N=25) had used IPAs before, with 9.4% (N=3) reporting frequent or very frequent use
none printacmref=false      [CHI '19 Workshops]  ACM SIGCHI International Conference on Human Factors in Computing SystemsMay 2019Glasgow, UK      978-1-4503-9999-9/18/06                                                  mluria@cs.cmu.edu    Human-Computer Interaction Institute   Carnegie Mellon University    johnz@cs.cmu.edu    Human-Computer Interaction Institute   Carnegie Mellon University    forlizzi.cmu.edu    Human-Computer Interaction Institute   Carnegie Mellon University                                                                 One of the challenges in conducting research on the intersection of the CHI and Human-Robot Interaction (HRI) communities is in addressing the gap of acceptable design research methods between the two
Among participants that reported previous experience with IPAs, 13 were native Mandarin speakers and 12 were native English speakers, with Siri (56%) being most commonly used, followed by Amazon Alexa (36%) and Google Assistant (12%).      §.§ Device conditions  In the experiment, participants interacted with Google Assistant, through both a Moto G6 smartphone (Smartphone condition) and a Google Home Mini smart speaker (Smart speaker condition) using a within participants design
Mozilla supported only some P3P features, but removed them by 2007
They created 14 five-person teams: balanced (uniform personality coverage) and imbalanced (excessive leader-type personalities) considering only the outcome of `DISC' <cit.> (dominance, inducement, submission, compliance) personality test and reported that balanced teams produce better work in terms of the quality of outcome compared to imbalance teams.        * Cognitive Biases: The study by Eickhoff2018 investigates cognitive biases and shows that cognitive biases negatively impact crowd task performance in relevance labelling
Other browsers shunned P3P and instead allowed users to set defaults like blocking all third party cookies <cit.>.  P3P-specific browser extensions provide a more meaningful perspective on conscious user adoption than usage statistics for each browser.  For example, Privacy Bird, an add-on for Internet Explorer 5 and 6 that displays a website's P3P policy in an easy to understand language, was downloaded 20k times in the first 6 months <cit.>.       §.§ Network Advertising Initiative (NAI) Opt-Out     AdTech vendors founded a self-regulatory body, the NAI, as a compromise following the Federal Trade Commission's (FTC) report on web privacy submitted to Congress in 1998 <cit.>.  The NAI established a system of opt-out cookies
Cognitive biases are known as systematic errors in thinking and can impact peoples everyday judgements and decisions.        * Cognitive Ability: AlagaraiSampath2014CognitivelyInspiredTask experiment with task presentation designs relating to cognitive features such as visual saliency of the target fields and working memory requirements
The order in which these were experienced was counterbalanced across L1 and L2 speaker groups
RtD can enable design researchers in the field of HRI to conduct exploratory design work that asks what is the right thing to design and share it within the community.         <ccs2012> <concept> <concept_id>10003120.10003123.10010860</concept_id> <concept_desc>Human-centered computing Interaction design process and methods</concept_desc> <concept_significance>500</concept_significance> </concept> <concept> <concept_id>10003120.10003123.10010860.10010859</concept_id> <concept_desc>Human-centered computing User centered design</concept_desc> <concept_significance>500</concept_significance> </concept> <concept> <concept_id>10003120.10003123.10010860.10010883</concept_id> <concept_desc>Human-centered computing Scenario-based design</concept_desc> <concept_significance>300</concept_significance> </concept> </ccs2012>   [500]Human-centered computing Interaction design process and methods [500]Human-centered computing User centered design [300]Human-centered computing Scenario-based design          Championing Research Through Design in HRI     Jodi Forlizzi     October 9, 2022 ==========================================       § INTRODUCTION  We agree with the workshop organizers that there are many challenges in working across the CHI and Human-Robot Interaction (HRI) communities
Finally, publishing RtD on HRI topics in CHI is likely to create a growing group of researchers that are on the intersection of the fields, and allow RtD to enter HRI more naturally.     ACM-Reference-Format                                               none printacmref=false      [CHI '19 Workshops]  ACM SIGCHI International Conference on Human Factors in Computing SystemsMay 2019Glasgow, UK      978-1-4503-9999-9/18/06                                                  mluria@cs.cmu.edu    Human-Computer Interaction Institute   Carnegie Mellon University    johnz@cs.cmu.edu    Human-Computer Interaction Institute   Carnegie Mellon University    forlizzi.cmu.edu    Human-Computer Interaction Institute   Carnegie Mellon University                                                                 One of the challenges in conducting research on the intersection of the CHI and Human-Robot Interaction (HRI) communities is in addressing the gap of acceptable design research methods between the two
Critics <cit.> note that the NAI's narrow definition of tracking would not cover many techniques observed in the wild <cit.>.   The NAI provide a list of all participating vendors, which was just 4 in 2004,  75 in 2010 <cit.> and stands at  participating vendors as of January 2021.  Websites and browsers do not need to adopt the NAI's system because it piggy-backs on existing browser cookie functionality
The study conducted on MTurk uses a transcription task and reports  design parameters that can improve task performance.     Goncalves2017TaskRouting investigated the impact of the cognitive ability of crowd worker performance and demonstrated that performance can be predicted from the results of cognitive ability tests
Google Assistant was selected because it is commonly used across both device types <cit.>.        §.§ Task  Participants were asked to conduct a total of 12 tasks with Google Assistant (six per device - all tasks are included in supplementary material)
In their study, they used 8 cognitive tests which included visual and fluency tasks and 8 different crowdsourcing task categories attempted by 24 participants in a lab setting
The NAI reported one million visits to the the opt-out page in 2006 <cit.> but we cannot differentiate unique visitors.  Returning to browser extensions, there were at least 44.9k users of the Targeted Advertising Cookie Opt-Out (TACO) add-on[<https://web.archive.org/web/20110920055245/https://addons.mozilla.org/en-us/firefox/addon/targeted-advertising-cookie-op/>], which maintained an up to date list of opt-out cookies.      §.§ Do Not Track (DNT)  Acknowledging the failure of P3P, the W3C created a working group in 2011 to standardize the Do Not Track (DNT) mechanism <cit.>.  DNT was less expressive than P3P.  Implementation involved browsers sending a  header with each HTTP request to signal that their user did not wish to be tracked.  Stakeholders disagreed on whether DNT should default to on or off <cit.>.  This opposition was part of the reason why the W3C working group was closed without success in 2019 <cit.>.  DNT was implemented in browsers by Microsoft, Apple, Mozilla and eventually Google <cit.>
Based on research identifying the most common tasks people conduct with IPAs <cit.> experimental tasks included 1) playing music, 2) setting an alarm, 3) converting values, 4) asking for the time in a particular location, 5) controlling device volume and 6) requesting weather information
RtD can enable design researchers in the field of HRI to conduct exploratory design work that asks what is the right thing to design and share it within the community.         <ccs2012> <concept> <concept_id>10003120.10003123.10010860</concept_id> <concept_desc>Human-centered computing Interaction design process and methods</concept_desc> <concept_significance>500</concept_significance> </concept> <concept> <concept_id>10003120.10003123.10010860.10010859</concept_id> <concept_desc>Human-centered computing User centered design</concept_desc> <concept_significance>500</concept_significance> </concept> <concept> <concept_id>10003120.10003123.10010860.10010883</concept_id> <concept_desc>Human-centered computing Scenario-based design</concept_desc> <concept_significance>300</concept_significance> </concept> </ccs2012>   [500]Human-centered computing Interaction design process and methods [500]Human-centered computing User centered design [300]Human-centered computing Scenario-based design          Championing Research Through Design in HRI     Jodi Forlizzi     October 9, 2022 ==========================================       § INTRODUCTION  We agree with the workshop organizers that there are many challenges in working across the CHI and Human-Robot Interaction (HRI) communities
Hettiachchi2019EffectofCognitive investigate the effect of cognitive abilities on crowdsourcing task performance in an online setting
Websites and third-party vendors could signal in an HTTP response header if they respected the user's DNT signal.  This signal was not exposed in any browser's user interface[<https://www.w3.org/TR/tracking-dnt/#responding>] (outside of add-ons), which meant users were largely unaware of website adoption
Each set of 6-tasks were used in only one of the device conditions
All tasks were delivered to participants as pictograms (see Figure 1)
While there is no evidence that shows a direct link between mood and task accuracy, the study reports that workers in a pleasant mood exhibit higher perceived benefits from completing tasks when compared to workers in an unpleasant mood.        * Work Device Features: Gadiraju2017ModusEnvironments show that crowd work device and its characteristics such as screen size, device speed have an impact on data quality
Only 9 companies issued public statements regarding support of DNT <cit.>
Hettiachchi2020CrowdTasker explore voice-based crowdsourcing, where workers complete crowd tasks through smart speakers and investigate if there is a performance difference compared to regular crowd work through desktop computers.         * Worker Context: Other contextual factors concerning the worker's current situation can also impact crowd task performance
This was so as to eliminate the potential influence of written task instructions on what both L1 and L2 participants might say to the IPAs, to more closely simulate natural query generation and to reduce potential difficulties translating task text for L2 speakers
In 2011, Mozilla reported DNT adoption by Firefox users to be at 17% in the US and 11% outside <cit.>, although this oversamples privacy aware users.      §.§ Global Privacy Control (GPC)   The unofficial GPC draft specification <cit.>, which was released in October 2020, continues the work of DNT in extending HTTP requests with a single bit value.   Perhaps the most important change is re-framing Do Not Track as a “Do Not Sell” and “Object To Processing” signal, which is closer to the language of the GDPR and the CCPA, which became effective in May 2018 and January 2020
This means GPC references (enforceable) laws, which DNT lacked.  As of February 2021, Mozilla and the Brave browser are listed as publicly supporting GPC, but only Brave have implemented it
Ikeda2017CrowdsourcingPerformance show that task completion rate decreases when workers are busy or with other people
These interviews lasted approximately 20 minutes and focused on 3 key topics: 1) general views towards IPAs; 2) experiences with the IPAs in the experiment; and 3) reflections on how they spoke to each system
Participants predominantly representing private firms from the advertising and publishing industries co-developed the TCF, which defines the legal terms and data processing purposes that users consent to and the format by which consent signals are stored and exchanged between third parties.  A new version () was introduced in 2020.   TCF is implemented by websites in the form of a consent dialog that does not require browser buy-in, much like NAI
So as to ensure that there were no linguistic barriers when expressing their opinions, L2 speaker interviews were conducted in Mandarin
§ CONCLUSIONS  In conclusion, we presented AirWare, a technology that fuses the output of an embedded smart-phone microphone and proximity sensor to recognize a gesture set of 21 in-air hand-gestures with 50.47% average true positive rate per gesture
Hettiachchi2020HowWork investigate workers' willingness to accept crowd tasks to understand the impact of context when tasks are available through a multitude of work devices.         * Skills: Prior work by Mavridis2016UsingCrowdsourcing estimates worker performance using a distance measure between the skills of the worker and the skills required for the specific task
While we show that combining two different sensor information streams can significantly increase performance, we conclude that the full 21 gesture vocabulary cannot be reliably classified for use in a deployed gesture recognition system
Similarly, Kumai2018Skill-and-Stress-AwareStreams model each skill with a numeric value
The results of this analysis are presented in the Results section below.       §.§ Procedure  The research received ethical approval through the University's low risk project ethics procedures [HS-E-19-127]
We refer to Hils et al. <cit.> for a visual depiction of the ecosystem.  The IAB maintains a public list of CMPs, which lists 119 participating providers as of February 2021.[<https://iabeurope.eu/cmp-list/>] A website wishing to implement the TCF independently must become a CMP,    otherwise they can out-source this to an existing CMP
In particular, AirWare can achieve true positive rates of greater than 80% true positive rate for Generic, Mapping, and Gaming gesture sets.   Using these gesture sets, AirWare can reliably classify a vocabulary of 16 unique gestures, with 4–7 gestures supported at any given time.   § DISCUSSIONS AND FUTURE WORK  Despite the good performance of AirWare, there are limitations in our study that we wish to specifically mention
For instance, 1 minus the average word error rate (WER) of a worker's typing results can represent their typing skill.       §.§.§ Worker Behaviour   Prior work shows that worker behaviour data can be used to estimate worker performance <cit.>
This was recorded using a Blue Yeti microphone and audio capture software (Audacity v. 2.3.0)
Rzeszotarski2011 proposed `task fingerprinting', a method that builds predictive models of task performance based on user behavioural traces
While a limitation, we foresee this process as something that could be incorporated into the calibration phase of the system.      We would also like to point out the problems with the Samsung S5 gesture sensing API
The largest CMPs are OneTrust and Quantcast, which account for 37.4% of all CMP implementations in the Tranco 100k (see Section <ref>).  To receive TCF consent signals from CMPs, AdTech vendors must register with the IAB and pay a yearly maintenance fee to join the Global Vendor List (GVL)[<https://iabeurope.eu/vendor-list/>]
We leave these limitations to future work.     § EXPERIMENTAL METHODOLOGY  In our pilot tests, we asked participants to perform each of the 21 gestures  in the way “that made the most sense to them.”   In this way, we sought to collect more realistic data where participants could be trained simply from a textual prompt of what the gesture was, without explicit training or demonstration
They were then thanked for participation and given a €10 voucher as an honorarium
Task fingerprinting has been shown to be effective for image tagging, part-of-speech classification, and passage comprehension tasks in Amazon Mechanical Turk.   Han2016 also reported that most of the worker behavioural factors are correlated with the output quality in an annotation task
While this is an additional limitation of the system because it imposes constraints on the gestures, such an instructional application would likely be required no matter what, as learning to perform 21 gestures for any user  without some instruction can be considered a daunting task.  In the first phase, 8 participants were recruited from university classes (age range: 19-30, Male:  60%)
In a different approach, Kazai2016 show how we can use the behaviours of trained professional workers as gold standard behaviour data to identify workers with poor performance in relevance labelling.   While other methods <cit.> aim to classify workers into either `good' or `bad' categories, Gadiraju2019CrowdPre-selection classify workers into five categories using behavioural traces from completed HITs
The study lasted approximately 40 minutes.     § RESULTS       §.§ General speaker differences  Irrespective of device type, clear differences emerged between L1 and L2 speakers' experiences when using IPAs
With , vendors can declare that their legal basis is flexible.  This means they would like to process data with the user's consent, but they can also perform (limited) processing based on a legitimate interest.   As the only exception,  removes the option for vendors to claim a legitimate interest in Purpose 1—“Store and/or access information on a device”—, possibly preempting an intervention by regulators.  The policy changes between  and  motivate measuring the transition.     § RELATED WORK   Section <ref> briefly describes the privacy practices employed by websites in order to motivate why privacy preferences matter.  Section <ref> surveys research into  privacy preferences including the previous five signals.  Section <ref> links the paper to the general question of why are technical standards adopted?      §.§ Privacy Practices   Researchers consistently demonstrate privacy eroding techniques deployed in the wild <cit.> motivated by online advertising business models <cit.>.  Personal data is leaked via social networks <cit.>, third-party web scripts <cit.>, apps <cit.>, software development kits <cit.>, and organizational breaches <cit.>.  The scale of tracking motivate re-designing systems to provide privacy guarantees.  For example, multihoming can be used to defend against fingerprinting <cit.> and trusted hardware can ensure compliance to stated privacy policies <cit.>.  Turning to so-called soft privacy, data processors are constrained by law and social norms.  These constraints are far from absolute.  For example, half of websites in a 2017 sample violated laws implementing the EU Privacy Directive by installing cookies before collecting user consent <cit.>.  This is likely because organizations do not incur significant costs following data breaches and privacy violations in terms of either regulatory fines or lost shareholder value <cit.>.  Nevertheless, firms' privacy practices are somewhat impacted by data processors' self-declared privacy policies <cit.> and even the privacy preferences expressed by users, to which we now turn.       §.§ Privacy Preferences   Interviews <cit.> and surveys <cit.> can use natural language to understand users' actual privacy preferences, which tend to contradict observed behavior <cit.>.  Privacy languages aim to express preferences more precisely than natural language.  For example, APPEL encodes user preferences to be compared against P3P policies <cit.>.  It could not express acceptable practices nor capture the realities of secondary sharing, which motivated XPref <cit.> and P2U <cit.>, respectively
Participants were instructed to hold the smart-phone in one hand and perform gestures “above” the phone with the other hand.   In the second phase, 13 participants were recruited (age range: 19-30, Male:  66%)
To predict task and worker accuracy in relevance labelling tasks, Goyal2018YourAnnotations uses action-based ( mouse movement in pixels in horizontal direction, total pixel scroll in vertical direction) and time-based ( fraction of the total time that was spent completing the HIT, mean time between two successive logged click events) features in their predictive model
These revolved around how each group approached the interaction, issues in turn taking, and the desire for design to reduce the effort involved in language production.      §.§.§ Interaction approaches:   Echoing previous literature on language production in speech interface <cit.> and IPA <cit.> use, L1 speakers prioritised vocal clarity, using correct English, brevity and planning when approaching interaction with both IPAs:    “I suppose it’s breaking it down and thinking about what the question actually is
I suppose what it is you want to know, how you should ask that if you were using proper English.” [P17-L1]     “[A]rticulate clearly and you know, think about how was, what was the simplest way possible to ask the question you know.” [P4-L1]        L2 speakers also heavily emphasised adaptations aimed at increasing the likelihood of being understood, but this was due to their own perceived language or speech limitations
On average, users  had some initial trouble learning how to manipulate the sensor for some gestures such as “tap” but were quickly able to alter their strategy to tap towards the top of the phone (where the IR sensor was located).  All users were able to successfully activate the IR sensor after two or three trials per gesture.       §.§ Gesture Vocabulary  Participants performed 21 different gestures as instructed on the screen of the phone via a custom data collection app
Goyal2018YourAnnotations argue that worker behaviour signals captured in a single session can be used to estimate the work quality when prior work history is unavailable.  Behavioural data like social media interests captured outside the crowdsourcing platforms have also been used to predict task performance <cit.>
Alternative languages focus on the usability for developers <cit.>, enabling audits <cit.>, and providing explanations <cit.>.  Privacy languages have been regularly surveyed by academics <cit.> but unfortunately there has been little adoption in practice <cit.>.  This motivates our focus on signals deployed in the Web ecosystem.  In terms of the first wave of signals, measurements of DNT and NAI opt-out adoption relied on organizations disclosing private data sources like Firefox configurations <cit.>, opt-out web page visits <cit.>, or the NAI's membership <cit.>.  P3P differed in that website adoption could be quantified via web scraping <cit.> often sampling via commercial website rankings.  Turning to the second wave, there are no GPC adoption studies because only a draft specification has been released so far.  The TCF ecosystem has been probed from a range of academic disciplines.   Legal methods are relevant to the semantic content of the signal.  For example, the purposes for collecting personal data standardized in the TCF may not be specific enough <cit.>.    User interface research is important because the TCF does not standardize how the consent decision is presented to users, which is known to be influential <cit.>.  At least two studies have found that consent dialogues used to collect consent under the TCF contain design choices that nudge users towards providing consent <cit.>.  Web scraping studies have focused on implementation problems with TCF <cit.> or the ecosystem of consent management providers (CMP) <cit.>.  These studies provide measurements of TCF in passing.  For example, both studies measure TCF vendor registrations and their claimed purposes for processing data for  <cit.> and both  and  <cit.>.  The latter study measures aggregate   adoption, whereas we measure and visualise at the vendor level.  Matte et al. <cit.> show how  adoption varies by top-level domain (TLD) and identify the most popular CMPs across the top 1k sites in five EU country code TLDs.   Hils et al. <cit.> use longitudinal measurements to show the market growth of six CMPs, highlighting how fast the ecosystem changes.     §.§ Standards Adoption   We build on a body of work emphasizing the role of institutions in technical standards adoption.  For example, many vendors initially saw the TCP/IP protocols as a nuisance <cit.>.  Leiner et al. <cit.> describe how a series of “conferences, tutorials, design meetings and workshops” were organized to educate a generation of vendors and engineers.   The rest is history.   The community was slow to turn to adoption questions like “What Makes for a Successful Protocol?”, which was posed by RFC  5218 in 2008.  Noting the qualitative nature of the resulting research, Nikkah et al. <cit.> provide an illuminating statistical analysis of the association between technical features of 250 RFCs and adoption success.  Analysing unchanging technical features cannot explain why it took two decades before IPv6 was widely adopted <cit.>.  Economic considerations like the scarcity of IPv4 addresses and the supply of compatible hardware can help explain when standards are adopted <cit.>.  Thus, standards should be considered in the context of wider ecosystems governed by economic incentives.  For example, HTTPS adoption relies on X.509 certificate infrastructure that was “in a sorry state” in 2011 with many websites relying on shared or invalid certificates <cit.>.  The situation was worse in the long tail likely because certificates are costly <cit.>.  Felt et al. <cit.> report on significant improvements in 2017 and attribute improvements in the long tail to institutions like Let's Encrypt and publishing platforms—we show how similar economic considerations explain why TCF was adopted.       §.§ Contribution  Our main empirical contribution involves measuring the adoption of privacy preference signals among websites as of February 2021.  Following the demise of P3P and DNT, the TCF has become dominant and the Global Privacy Control is still in its infancy.  We explore variables explaining which websites adopt TCF, and also longitudinally measure migration to a new version ().      This work differs from existing work by focusing exclusively on the adoption of privacy preference signals.  We largely ignore the actors <cit.> and interfaces <cit.> harvesting such signals and instead focus on which factors (e.g. website type, popularity, and partners) are associated with TCF adoption.  Further, we are the first to systematize strands of research ranging from works in the late 1990s to post-GDPR studies.  Finally, we provide the first results about migrating between versions of such signals using our the longitudinal methodology introduced in <cit.>.  Our previous work focuses on detecting specific CMPs, some of whom collect non-TCF signals exclusively or only collect TCF signals for a subset of customers.                       § METHODS   We adopt a mixed approach[ 	Supplementary Material:  <https://github.com/mhils/pets2021-privacy-preference-signals> 	 ] conducting both longitudinal high-frequency measurements to determine historic adoption of TCF and migration between versions, as well as a large-scale snapshot measurement to examine site-specific factors that may influence adoption.  Section <ref> describes our snapshot measurement of the Tranco 100k toplist
In all, each participant performed between 5 and 10 iterations of each gesture
For instance, rather than adapting vocabulary to try and improve system performance (as is commonly mentioned in previous work <cit.>) L2 speakers instead altered their vocabulary based on whether or not they knew a particular word:   “I tend to change the words I used
Section <ref> explains how we use the Netograph platform to conduct longitudinal high-frequency measurements.     §.§ Snapshot Measurements   To measure the prevalence of TCF and its different versions on the web, we crawled the top 100k entries from the Tranco toplist, which aggregates the ranks from the lists provided by Alexa, Cisco Umbrella, Majestic, and Quantcast <cit.>
Similarly, Barbosa2019RehumanizedLearning introduces a framework where the worker pool for each task can be constrained using multiple factors such as demographics, experience and skills
For example, when I asked the devices to change the volume, I didn't know the word ‘volume’ so I changed it to ‘voice’ or ‘sound’.” [P9-L2]   L2 speakers tried to adopt strategies to overcome this, especially when the IPAs repeatedly did not recognise their utterances, although these were unsuccessful:    “The recognition of people’s names and place names has a low success rate
We let participants perform gestures for 45 minutes and then ended the session
Our automated browser crawls were performed in February 2021 using a Tranco toplist from January 2020[Available at <https://tranco-list.eu/list/K8JW>]
Table <ref> provides a brief summary of the worker performance estimation and assignment strategy of each method we discuss in this section.      cccp1cmp3.2cmp3.3cmp3.3cm     An overview of worker performance estimation and assignment strategies of assignment methods.       3p1cmAssignment Problem     Reference     Performance Estimation     Assignment Strategy     Method Maturity and Evaluation            [t]2.5mm[origin=c]90Task     [t]2.5mm[origin=c]90Question              [t]2.5mm[origin=c]90Plurality                     <cit.>     Requesters manually evaluate the answers.      Based on the online primal-dual framework.     Basic Research
On average, each participant performed about 250 gestures
We used this older toplist dated shortly before publishers transitioned to  in order to avoid survivorship bias in our observations.  Picking a later toplist would over-sample websites created post-2020 who are certain to adopt  and de facto avoid a migration decision
In contrast, another method could aim to achieve the highest possible data quality with a set budget.  Ho2012OnlineMarkets propose a task assignment method based on the online primal-dual framework, which has been previously utilised for different online optimisation problems
But the devices cannot understand that.” [P9-L2]   L2 speakers were also highly sensitive to their pronunciation or need to retrieve the correct words in interaction, which took up considerable time when interacting with the IPAs:    ”... sometimes it cannot understand some pronunciation by non-native English speakers, and it cannot help you pronounce the words you don’t know.” [P9-L2]         “As a non-native English speaker, I have a hard time on proper nouns ..
Our toplist and a current Tranco toplist (Tranco id KGNW from Feb. 19th 2021) overlap by 76.5%.  We first converted the Tranco list of domains to a list of URLs that can be crawled
Maybe the devices cannot recognize due to this issue, and it may waste a lot of time.” [P4-L2]       §.§.§ Waking and turn taking:  There were also clear differences between L1 and L2 speakers when it came to waking the device and managing turn taking with the IPAs
Ho2013AdaptiveClassification further investigate heterogeneous task assignment in classification tasks with binary labels
Assadi2015OnlineMarkets propose an online algorithm that can be used by a requester to maximise the number of tasks allocated with a fixed budget
We then isolate a band of magnitudes around the frequency in a range of frequency bins above and below f_0
For each domain, we attempted to establish a TLS and a TCP connection with www.domain and domain on port 443 and 80, respectively.    This was repeated three times over a week to catch temporary service disruptions
L2 speakers regularly felt like they struggled to wake the Assistants in both device conditions:    “I feel that I wake up a few times and it ignored me ... like you have finished the commands but it maybe didn’t get you.” [P14-L2]   During interactions, L2 speakers suggested they sometimes needed extra time to formulate an utterance and that this was not taken into consideration by the system
In a different approach for task assignment, Mo2013CrosstaskCrowdsourcing apply a hierarchical Bayesian transfer learning model
The command I said before is wasted.” [P4-L2]    “[W]hen I didn’t finish my sentences and the machine `thinks' that I’m finished
The number of bins above and below the f_0 is a grid-searched parameter in our analysis
It’s like, the IPAs can only analyze the sentences you said.” [P14-L2]   In contrast, L1 speakers perceived the delay between speaking to the device and it responding as too long, making the interaction seem slow:   “[A]gain it would be the delayed interaction
However, their real-world evaluation is limited to a single scenario with one source task and one target task.   While most methods focus on a predefined set of tasks, Dickerson2018AssigningArrivals examine task assignment when tasks are not known a-priori
We found that using 16 bins above and below the f_0 is sufficient for classification
Websites were opened using Google Chrome on Linux with its current default user agent,fn:supplements a desktop resolution of 1024×800, and  as the preferred browser language
What I think is going on there is it is trying to figure out whether or not you finished a sentence?” [P9-L1]    “It’s too slow to react, because it can’t keep up with me
Difallah2013Pick-a-crowd:Networks present a system where tasks are allocated based on worker profile data such as interested topics captured from a social media network
During this feature extraction, we also eliminate the magnitude of f_0 from the spectrogram, as the value is relatively constant in magnitude and therefore has limited predictive capability as a feature.   After processing the STFT, we process the features extracted from the Samsung Galaxy S5's IR sensor
We correlated the reported CMP ids with contacted domains and did not find any evidence of misrepresentation.  The adoption of TCF is naturally higher on some types of websites, such as those who typically display paid advertisements.  To quantify this, we divided the Tranco 10k toplist into categories with the help of Symantec Rulespace <cit.>, a categorization database already used in related work by Sanchez-Rola et al. <cit.>
The notification includes the speed (a normalized value between 0 and 100) and angle of any detected movements
Similarly, Zhao2014SocialTransfer:Crowdsourcing propose `Social Transfer graph' for task matching
I’d much rather type...” [P1-L1]   This led L1 speakers to question whether the devices were working correctly, increasing frustration:     “[T]here were times when I wasn’t sure if you know it was just not working or something? Because I really clearly said what I wanted it to do and it didn’t, you know, react.” [P4-L1]    “It’s more frustrating I suppose, the lack of proper response to it, there was no, ‘don’t understand the questions’ ... the feedback didn’t seem adequate.” [P17-L1]       §.§.§ Reducing the burden of production:  L2 speakers also tended to emphasise ways that IPAs could be improved, with a focus on reducing the level of language production needed as well as ways to support word recall and gaps in lexical knowledge
We limit our analysis to the Tranco 10k as a non-negligible share of websites (11.7%) in the top 100k is not categorized, compared to only 2.4% for the top 10k websites
When we required the user to activate the IR sensor, segmentation was straightforward: we buffer the audio signal 1.25 seconds before and after the IR activation
The general applicability of such methods raises numerous practical and ethical considerations.   Mavridis2016UsingCrowdsourcing introduced a skill-based task assignment model
Frustration with having to reproduce or reformulate queries from scratch was common, with L2 speakers suggesting that it would be helpful if IPAs were aware of previous attempts to make a query:   “It’s, maybe I can meet some words problems
To determine a lower bound, we took all third-party domains that were included on at least 1.000 websites in the Tranco 100k (158 domains) and manually removed shared resources such as content delivery networks which may not constitute tracking (12 domains)
When we did not require the IR sensor to activate, we buffered 1.25 seconds before and after any “event of interest.”  We define this event to be when either the IR sensor is activated or when the magnitude of frequency bins directly greater than and less than f_0 increase by 10 dB
We then determined for each website if any of the remaining 146 third parties were embedded
Ikeda2016CollaborativeCrowd4U propose a task assignment framework that can decompose complex tasks and support sequential, simultaneous and hybrid worker collaboration schemes
That will be better.” [P7-L2]      “After I finished the question, for example, when I asked the time of a city, and got an answer for a wrong city, then there is no need to ask the whole question again
This is especially true for mobile devices (1) when the  device is small and touch is harder to use without occluding screen content (such as a watch) or  (2) in situational impairments, like wearing gloves or cooking, when hands get dirty and touching a smart-phone or tablet is not desired <cit.>
I should only need to emphasize the city name.” [P1-L2]    Similarly, to support L2 issues with word selection, participants suggested that contextual options could be provided in cases where the intent of the query was recognised but users were struggling with the specific noun required:   “When I don't know that word I can say `please transfer Celsius degree to another temperature unit'...for example, they can list all temperatures for you.” [P8-L2]    “For example, if you say some unclear words and the devices can show you the possible choices or match the most possible option or something.” [P16-L2]   This desire to support the interaction with suggestions was not identified by L1 users, who instead suggested better recognition of wider forms of language such as colloquialisms:    “[T]hey're interesting I suppose in how they try to make you speak in a different way that’s not natural to you
More specifically, we present AirWare, a system that fuses the information from the on-board infrared (IR) proximity sensor of a Samsung Galaxy S5 with the Doppler shifts detected by the microphone
In a manual inspection of 50 randomly picked domains with and 50 domains without “cookie” in their DOM tree, we found five domains that had a “Cookie Notice” link in their footer (but no dialog) and no false negatives (which yields a 5% error rate overall)
In contrast, Schmitz2018OnlineCrowdsourcing look at non-decomposable macro-tasks like document drafting
Like previous work <cit.> we play an inaudible tone from the speakers and record from the microphone continuously.   Using signal processing and machine learning, we fuse the parameters of the IR proximity sensor with the Doppler features to predict a large vocabulary of different in-air gestures.   Our approach differs from previous work in that we (1) combine complementary sensors that are already embedded in the mobile phone and (2) attempt to classify a relatively large vocabulary of different gestures
They make your colloquialism sound strange and they make you pronounce things in that curious kind of way.” [P17-L1]    “Improved? I’m not too sure, I suppose it involves listening to more conversations and getting a colloquial idea than just proper English.” [P5-L1]       §.§ Device-specific differences  Our analysis discovered a marked difference in the way that both speaker types experienced IPA use through the smart speaker and smartphone respectively
Among the L1 speakers, 75% (N=12) preferred using Google Assistant on the smart speaker, whilst 63% of L2 speakers (N=10) preferred using the Assistant on the smartphone
Most previous works only cover a few basic interactions (like panning), which does not provide a rich interaction modality.     To inform the design and evaluate AirWare, we conducted a user study with 13 participants that performed each gesture several times (load balanced in terms of presentation order)
Prior work by Difallah2016SchedulingHITs investigates task scheduling in crowdsourcing platforms and shows that scheduling can help minimise the overall task latency, while significantly improving the worker productivity captured through average task execution time
